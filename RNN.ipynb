{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "caa7e63f",
      "metadata": {
        "id": "caa7e63f"
      },
      "source": [
        "\n",
        "\n",
        "### Based on the example from Tensorflow's text generation with RNN:\n",
        "### https://www.tensorflow.org/text/tutorials/text_generation\n",
        "\n",
        "### Text used for the RNN model: The entire script from Lord of the Rings: Fellowship of the Ring"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VvtJIZtltUA2",
      "metadata": {
        "id": "VvtJIZtltUA2"
      },
      "source": [
        "# Changes made to the code:\n",
        "## If there are modifications made for this code, then it would be the length of the example sequence for input text processing and the number of epochs to run for training. Also, the changes made so far are the example text vector ['abcdefghij', 'wxyz'] and the temperature parameter for the one-step RNN model class. For the latter, I choose the following values to try out: 1.0, 0.9, 0.8, 0.7, 0.6, and 0.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4d6e219",
      "metadata": {
        "id": "a4d6e219"
      },
      "outputs": [],
      "source": [
        "# Import the following modules over\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Try to open the text file if it exists.\n",
        "input_file = \"rings.txt\"\n",
        "corpus_raw = open(input_file, \"r\", encoding=\"utf-8\").read()\n",
        "\n",
        "# Print out the sample text file.\n",
        "#print(corpus_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deeff9dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deeff9dc",
        "outputId": "fc666a52-0886-42d0-8abd-eedcdc699012"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'Ó', 'á', 'â', 'ä', 'é', 'ë', 'í', 'ó', 'ú', 'û', '–']\n",
            "Total length of text:  1021058\n",
            "Total number of characters found:  90\n"
          ]
        }
      ],
      "source": [
        "# Obtain the list of characters included in the raw text.\n",
        "# Be sure to use set() to filter out duplicates.\n",
        "characters = sorted(list(set(corpus_raw)))\n",
        "\n",
        "# Print out the list of characters found in the raw text.\n",
        "print(characters)\n",
        "\n",
        "# Also obtain the total length of the text and the characters.\n",
        "print(\"Total length of text: \", len(corpus_raw))\n",
        "print(\"Total number of characters found: \", len(characters))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84fbbc7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84fbbc7b",
        "outputId": "a056906e-3f76-4291-c651-684f1c8223c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Three Rings for the Elven-kings under the sky,\n",
            "               Seven for the Dwarf-lords in their halls of stone,\n",
            "            Nine for Mortal Men doomed to die,\n",
            "              One for the Dark Lord on his dark throne\n",
            "           In the Land of Mordor where the Shadows lie.\n",
            "               One Ring to rule them all, One Ring to find them,\n",
            "               One Ring to bring them all and in the darkness bind them\n",
            "           In the Land of Mordor where the Shadows lie.\n",
            "           \n",
            "FOREWORD\n",
            "\n",
            "This tale grew\n"
          ]
        }
      ],
      "source": [
        "# Print out the first 500 characters of the text.\n",
        "print(corpus_raw[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11f95f52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11f95f52",
        "outputId": "411508e6-339b-4064-fbb0-51f1685cf02f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g', b'h', b'i', b'j'],\n",
              " [b'w', b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Vectorize the text by converting the string into a numerical form.\n",
        "sample_text = ['abcdefghij', 'wxyz']\n",
        "num_chars = tf.strings.unicode_split(sample_text, input_encoding=\"UTF-8\")\n",
        "num_chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b9a2dbe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b9a2dbe",
        "outputId": "32142230-b0e5-4c3b-a6ca-dee307f6939d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[54, 55, 56, 57, 58, 59, 60, 61, 62, 63], [76, 77, 78, 79]]>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id_from_characters = tf.keras.layers.StringLookup(vocabulary=list(characters))\n",
        "ids = id_from_characters(num_chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e877107f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e877107f",
        "outputId": "797576d9-3b40-4063-b782-d614fe5a0489"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g', b'h', b'i', b'j'],\n",
              " [b'w', b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "characters_from_id = tf.keras.layers.StringLookup(vocabulary=id_from_characters.get_vocabulary(), invert=True)\n",
        "characters = characters_from_id(ids)\n",
        "characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f827c832",
      "metadata": {
        "id": "f827c832"
      },
      "outputs": [],
      "source": [
        "# Convert the corresponding string ids back into text form.\n",
        "def text_from_id(ids):\n",
        "    return tf.strings.reduce_join(characters_from_id(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a4db834",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a4db834",
        "outputId": "858e1afd-1bfe-448f-9be7-6f786a3ebaed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1021058,), dtype=int64, numpy=array([45, 61, 71, ..., 32, 10,  1])>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_text_id = id_from_characters(tf.strings.unicode_split(corpus_raw, 'UTF-8'))\n",
        "all_text_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31b96fde",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31b96fde",
        "outputId": "f4cbce1e-49f3-42ea-b767-bbc0fea0c3fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T\n",
            "h\n",
            "r\n",
            "e\n",
            "e\n",
            " \n",
            "R\n",
            "i\n",
            "n\n",
            "g\n",
            "s\n",
            " \n",
            "f\n",
            "o\n",
            "r\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "E\n",
            "l\n",
            "v\n",
            "e\n",
            "n\n"
          ]
        }
      ],
      "source": [
        "# Try to print out the first 25 characters from raw text via tensor slices.\n",
        "id_dataset = tf.data.Dataset.from_tensor_slices(all_text_id)\n",
        "for curr_id in id_dataset.take(25):\n",
        "    print(characters_from_id(curr_id).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d763d8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d763d8c",
        "outputId": "dedf188d-d9eb-446e-c5ac-a180a51c51e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'T' b'h' b'r' b'e' b'e' b' ' b'R' b'i' b'n' b'g' b's' b' ' b'f' b'o'\n",
            " b'r' b' ' b't' b'h' b'e' b' ' b'E' b'l' b'v' b'e' b'n' b'-' b'k' b'i'\n",
            " b'n' b'g' b's' b' ' b'u' b'n' b'd' b'e' b'r' b' ' b't' b'h' b'e' b' '\n",
            " b's' b'k' b'y' b',' b'\\n' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' '\n",
            " b' ' b' ' b' ' b' ' b' ' b' ' b'S' b'e' b'v' b'e' b'n' b' ' b'f' b'o'\n",
            " b'r' b' ' b't' b'h' b'e' b' ' b'D' b'w' b'a' b'r' b'f' b'-' b'l' b'o'\n",
            " b'r' b'd' b's' b' ' b'i' b'n' b' ' b't' b'h' b'e' b'i' b'r' b' ' b'h'\n",
            " b'a' b'l' b'l' b's' b' ' b'o' b'f' b' ' b's' b't' b'o' b'n' b'e' b','\n",
            " b'\\n' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b'N'\n",
            " b'i' b'n' b'e' b' ' b'f' b'o' b'r' b' ' b'M' b'o' b'r' b't' b'a' b'l'\n",
            " b' ' b'M' b'e' b'n' b' ' b'd' b'o' b'o' b'm' b'e' b'd' b' ' b't' b'o'\n",
            " b' ' b'd' b'i' b'e' b',' b'\\n' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' '\n",
            " b' ' b' ' b' ' b' ' b' ' b' ' b'O' b'n' b'e' b' ' b'f' b'o' b'r' b' '\n",
            " b't' b'h' b'e' b' ' b'D' b'a' b'r' b'k' b' ' b'L' b'o' b'r' b'd' b' '\n",
            " b'o' b'n' b' ' b'h' b'i'], shape=(201,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "# Now build a sequence of the first 200 characters.\n",
        "sequence_len = 200\n",
        "each_example = len(corpus_raw)\n",
        "sequences = id_dataset.batch(sequence_len+1, drop_remainder=True)\n",
        "\n",
        "for curr_seq in sequences.take(1):\n",
        "    print(characters_from_id(curr_seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5d9eaa7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5d9eaa7",
        "outputId": "85d8f896-bcf4-4174-d5a9-0da9a5dda6a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'Three Rings for the Elven-kings under the sky,\\n               Seven for the Dwarf-lords in their halls of stone,\\n            Nine for Mortal Men doomed to die,\\n              One for the Dark Lord on hi'\n",
            "b's dark throne\\n           In the Land of Mordor where the Shadows lie.\\n               One Ring to rule them all, One Ring to find them,\\n               One Ring to bring them all and in the darkness bind'\n",
            "b' them\\n           In the Land of Mordor where the Shadows lie.\\n           \\nFOREWORD\\n\\nThis tale grew in the telling, until it became a history of the Great War of the Ring and included many glimpses of t'\n",
            "b'he yet more ancient history that preceded it. It was begun soon after _The Hobbit_ was written and before its publication in 1937; but I did not go on with this sequel, for I wished first to complete a'\n",
            "b'nd set in order the mythology and legends of the Elder Days, which had then been taking shape for some years. I desired to do this for my own satisfaction, and I had little hope that other people would'\n"
          ]
        }
      ],
      "source": [
        "for curr_seq in sequences.take(5):\n",
        "    print(text_from_id(curr_seq).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd8ca678",
      "metadata": {
        "id": "cd8ca678"
      },
      "outputs": [],
      "source": [
        "def split_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f1dcb43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f1dcb43",
        "outputId": "cc3a8a63-5efa-4d90-c7fa-73f011b18377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:  b'Three Rings for the Elven-kings under the sky,\\n               Seven for the Dwarf-lords in their halls of stone,\\n            Nine for Mortal Men doomed to die,\\n              One for the Dark Lord on h'\n",
            "Target:  b'hree Rings for the Elven-kings under the sky,\\n               Seven for the Dwarf-lords in their halls of stone,\\n            Nine for Mortal Men doomed to die,\\n              One for the Dark Lord on hi'\n"
          ]
        }
      ],
      "source": [
        "text_dataset = sequences.map(split_target)\n",
        "for input_text, target_text in text_dataset.take(1):\n",
        "    print(\"Input: \", text_from_id(input_text).numpy())\n",
        "    print(\"Target: \", text_from_id(target_text).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afc4123e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afc4123e",
        "outputId": "d3daeb6b-62a7-49fd-db96-4f8e7aa46731"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 200), dtype=tf.int64, name=None), TensorSpec(shape=(64, 200), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    text_dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1a31270",
      "metadata": {
        "id": "b1a31270"
      },
      "outputs": [],
      "source": [
        "vocab = sorted(set(corpus_raw))\n",
        "vocab_size = len(vocab)\n",
        "embedding_dimension=256\n",
        "rnn_units=1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c5f1602",
      "metadata": {
        "id": "0c5f1602"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc273d46",
      "metadata": {
        "id": "dc273d46"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(id_from_characters.get_vocabulary()),\n",
        "    embedding_dim=embedding_dimension,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceda7e97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceda7e97",
        "outputId": "723b3b4f-5cc0-4e7b-a281-90763606312f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 200, 91) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a620c25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a620c25",
        "outputId": "6d95bd99-7b4f-4796-d2ef-49afcfe7243b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  23296     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  93275     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,054,875\n",
            "Trainable params: 4,054,875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e64b7c35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e64b7c35",
        "outputId": "b536e157-ea5f-446a-864c-785029b12206"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([89,  8, 20,  0, 88, 26, 82, 88, 41, 50, 66,  2, 79, 16, 58,  2, 18,\n",
              "       83, 25, 58, 26, 45, 12, 60, 65,  0, 47, 71, 52, 71, 29, 34, 55, 76,\n",
              "       39, 80, 47, 76, 89,  6, 65, 38, 36, 35, 58, 65, 16, 77, 62, 80, 74,\n",
              "       76, 86, 56,  4,  1, 63, 85, 66, 56, 18, 52, 10, 84, 67, 16, 40, 57,\n",
              "       37, 41, 17, 24, 63, 20, 43,  5, 44,  2, 63, 23,  4,  7, 60, 84, 47,\n",
              "       36, 55, 80, 60, 16, 85, 70, 45, 74, 56, 75, 76, 22, 85, 86, 36, 33,\n",
              "       72, 33, 52, 53, 36, 11, 30,  6, 83, 34, 63, 37,  8, 48, 28,  1, 72,\n",
              "       77, 58, 16, 60, 75, 64, 44, 64, 77,  2, 30, 70, 40, 89, 13, 46, 43,\n",
              "       39, 41, 61, 37, 25, 56,  5, 25, 31, 90, 89, 29, 77, 69, 30, 13, 53,\n",
              "       62, 90,  9, 49, 77, 14, 82, 30, 58, 75, 45, 27, 26, 56, 32, 16, 66,\n",
              "       84,  9, 35, 77,  6, 46, 35, 42, 30, 41, 62, 32, 31, 28, 54, 15, 23,\n",
              "       28, 10, 54, 65, 12, 82, 16, 38, 69, 14, 44, 52,  3])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd28ae2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd28ae2f",
        "outputId": "04eb0292-a490-4c9b-efd1-69af9dcea8b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b' the background of their minds and memories that was very similar. They understood one another remarkably well, very much better than a hobbit would understand, say, a Dwarf, or an Orc, or even an Elf'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'\\xc3\\xbb,8[UNK]\\xc3\\xbaA\\xc3\\xa2\\xc3\\xbaPYm z4e 6\\xc3\\xa4?eAT0gl[UNK]Vr_rDIbwN\\xc3\\x93Vw\\xc3\\xbb(lMKJel4xi\\xc3\\x93uw\\xc3\\xadc\"\\nj\\xc3\\xabmc6_.\\xc3\\xa9n4OdLP5=j8R\\'S j;\")g\\xc3\\xa9VKb\\xc3\\x93g4\\xc3\\xabqTucvw:\\xc3\\xab\\xc3\\xadKHsH_`K/E(\\xc3\\xa4IjL,WC\\nsxe4gvkSkx EqO\\xc3\\xbb1URNPhL?c\\'?F\\xe2\\x80\\x93\\xc3\\xbbDxpE1`i\\xe2\\x80\\x93-Xx2\\xc3\\xa2EevTBAcG4m\\xc3\\xa9-Jx(UJQEPiGFCa3;C.al0\\xc3\\xa24Mp2S_!'\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_id(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_id(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06a0dd09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06a0dd09",
        "outputId": "ca584c0c-16d6-4e38-9b4e-7af1ccfb09e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 200, 91)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.5118217, shape=(), dtype=float32)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "91.08761"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)\n",
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce32c023",
      "metadata": {
        "id": "ce32c023"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efce84d2",
      "metadata": {
        "id": "efce84d2"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b9a6a87",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b9a6a87",
        "outputId": "15bd6e8b-eead-48dd-fd49-fb2b3fa3b55e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "79/79 [==============================] - 25s 263ms/step - loss: 2.9964\n",
            "Epoch 2/100\n",
            "79/79 [==============================] - 22s 261ms/step - loss: 2.2272\n",
            "Epoch 3/100\n",
            "79/79 [==============================] - 23s 266ms/step - loss: 1.9535\n",
            "Epoch 4/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 1.7351\n",
            "Epoch 5/100\n",
            "79/79 [==============================] - 22s 266ms/step - loss: 1.5642\n",
            "Epoch 6/100\n",
            "79/79 [==============================] - 23s 266ms/step - loss: 1.4430\n",
            "Epoch 7/100\n",
            "79/79 [==============================] - 23s 268ms/step - loss: 1.3584\n",
            "Epoch 8/100\n",
            "79/79 [==============================] - 22s 261ms/step - loss: 1.2947\n",
            "Epoch 9/100\n",
            "79/79 [==============================] - 22s 262ms/step - loss: 1.2441\n",
            "Epoch 10/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 1.2029\n",
            "Epoch 11/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 1.1663\n",
            "Epoch 12/100\n",
            "79/79 [==============================] - 22s 266ms/step - loss: 1.1339\n",
            "Epoch 13/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 1.1042\n",
            "Epoch 14/100\n",
            "79/79 [==============================] - 23s 267ms/step - loss: 1.0759\n",
            "Epoch 15/100\n",
            "79/79 [==============================] - 22s 262ms/step - loss: 1.0467\n",
            "Epoch 16/100\n",
            "79/79 [==============================] - 22s 263ms/step - loss: 1.0187\n",
            "Epoch 17/100\n",
            "79/79 [==============================] - 23s 266ms/step - loss: 0.9915\n",
            "Epoch 18/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.9631\n",
            "Epoch 19/100\n",
            "79/79 [==============================] - 23s 267ms/step - loss: 0.9333\n",
            "Epoch 20/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.9032\n",
            "Epoch 21/100\n",
            "79/79 [==============================] - 22s 266ms/step - loss: 0.8717\n",
            "Epoch 22/100\n",
            "79/79 [==============================] - 22s 260ms/step - loss: 0.8391\n",
            "Epoch 23/100\n",
            "79/79 [==============================] - 22s 262ms/step - loss: 0.8063\n",
            "Epoch 24/100\n",
            "79/79 [==============================] - 23s 266ms/step - loss: 0.7701\n",
            "Epoch 25/100\n",
            "79/79 [==============================] - 23s 265ms/step - loss: 0.7338\n",
            "Epoch 26/100\n",
            "79/79 [==============================] - 22s 266ms/step - loss: 0.6977\n",
            "Epoch 27/100\n",
            "79/79 [==============================] - 23s 267ms/step - loss: 0.6619\n",
            "Epoch 28/100\n",
            "79/79 [==============================] - 23s 268ms/step - loss: 0.6248\n",
            "Epoch 29/100\n",
            "79/79 [==============================] - 22s 262ms/step - loss: 0.5914\n",
            "Epoch 30/100\n",
            "79/79 [==============================] - 22s 262ms/step - loss: 0.5569\n",
            "Epoch 31/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.5261\n",
            "Epoch 32/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.4961\n",
            "Epoch 33/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.4668\n",
            "Epoch 34/100\n",
            "79/79 [==============================] - 23s 267ms/step - loss: 0.4415\n",
            "Epoch 35/100\n",
            "79/79 [==============================] - 23s 267ms/step - loss: 0.4195\n",
            "Epoch 36/100\n",
            "79/79 [==============================] - 22s 262ms/step - loss: 0.3996\n",
            "Epoch 37/100\n",
            "79/79 [==============================] - 22s 261ms/step - loss: 0.3777\n",
            "Epoch 38/100\n",
            "79/79 [==============================] - 23s 266ms/step - loss: 0.3602\n",
            "Epoch 39/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.3486\n",
            "Epoch 40/100\n",
            "79/79 [==============================] - 23s 266ms/step - loss: 0.3335\n",
            "Epoch 41/100\n",
            "79/79 [==============================] - 22s 266ms/step - loss: 0.3231\n",
            "Epoch 42/100\n",
            "79/79 [==============================] - 22s 267ms/step - loss: 0.3090\n",
            "Epoch 43/100\n",
            "79/79 [==============================] - 22s 261ms/step - loss: 0.2968\n",
            "Epoch 44/100\n",
            "79/79 [==============================] - 22s 261ms/step - loss: 0.2879\n",
            "Epoch 45/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.2821\n",
            "Epoch 46/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.2758\n",
            "Epoch 47/100\n",
            "79/79 [==============================] - 23s 266ms/step - loss: 0.2667\n",
            "Epoch 48/100\n",
            "79/79 [==============================] - 22s 266ms/step - loss: 0.2641\n",
            "Epoch 49/100\n",
            "79/79 [==============================] - 22s 266ms/step - loss: 0.2612\n",
            "Epoch 50/100\n",
            "79/79 [==============================] - 22s 262ms/step - loss: 0.2547\n",
            "Epoch 51/100\n",
            "79/79 [==============================] - 22s 262ms/step - loss: 0.2471\n",
            "Epoch 52/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.2418\n",
            "Epoch 53/100\n",
            "79/79 [==============================] - 23s 269ms/step - loss: 0.2336\n",
            "Epoch 54/100\n",
            "79/79 [==============================] - 23s 267ms/step - loss: 0.2323\n",
            "Epoch 55/100\n",
            "79/79 [==============================] - 23s 267ms/step - loss: 0.2289\n",
            "Epoch 56/100\n",
            "79/79 [==============================] - 23s 267ms/step - loss: 0.2233\n",
            "Epoch 57/100\n",
            "79/79 [==============================] - 22s 261ms/step - loss: 0.2214\n",
            "Epoch 58/100\n",
            "79/79 [==============================] - 22s 262ms/step - loss: 0.2170\n",
            "Epoch 59/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.2201\n",
            "Epoch 60/100\n",
            "79/79 [==============================] - 22s 264ms/step - loss: 0.2189\n",
            "Epoch 61/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.2151\n",
            "Epoch 62/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.2145\n",
            "Epoch 63/100\n",
            "79/79 [==============================] - 23s 266ms/step - loss: 0.2147\n",
            "Epoch 64/100\n",
            "79/79 [==============================] - 22s 261ms/step - loss: 0.2149\n",
            "Epoch 65/100\n",
            "79/79 [==============================] - 22s 261ms/step - loss: 0.2141\n",
            "Epoch 66/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.2124\n",
            "Epoch 67/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.2128\n",
            "Epoch 68/100\n",
            "79/79 [==============================] - 23s 267ms/step - loss: 0.2075\n",
            "Epoch 69/100\n",
            "79/79 [==============================] - 23s 267ms/step - loss: 0.2055\n",
            "Epoch 70/100\n",
            "79/79 [==============================] - 23s 267ms/step - loss: 0.2023\n",
            "Epoch 71/100\n",
            "79/79 [==============================] - 22s 260ms/step - loss: 0.1951\n",
            "Epoch 72/100\n",
            "79/79 [==============================] - 22s 261ms/step - loss: 0.1953\n",
            "Epoch 73/100\n",
            "79/79 [==============================] - 23s 266ms/step - loss: 0.1912\n",
            "Epoch 74/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.1896\n",
            "Epoch 75/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.1916\n",
            "Epoch 76/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.1981\n",
            "Epoch 77/100\n",
            "79/79 [==============================] - 23s 267ms/step - loss: 0.2050\n",
            "Epoch 78/100\n",
            "79/79 [==============================] - 22s 261ms/step - loss: 0.2095\n",
            "Epoch 79/100\n",
            "79/79 [==============================] - 22s 261ms/step - loss: 0.2062\n",
            "Epoch 80/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.2041\n",
            "Epoch 81/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.2033\n",
            "Epoch 82/100\n",
            "79/79 [==============================] - 22s 266ms/step - loss: 0.2033\n",
            "Epoch 83/100\n",
            "79/79 [==============================] - 23s 266ms/step - loss: 0.2001\n",
            "Epoch 84/100\n",
            "79/79 [==============================] - 23s 268ms/step - loss: 0.1968\n",
            "Epoch 85/100\n",
            "79/79 [==============================] - 22s 262ms/step - loss: 0.1893\n",
            "Epoch 86/100\n",
            "79/79 [==============================] - 22s 261ms/step - loss: 0.1823\n",
            "Epoch 87/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.1784\n",
            "Epoch 88/100\n",
            "79/79 [==============================] - 22s 264ms/step - loss: 0.1707\n",
            "Epoch 89/100\n",
            "79/79 [==============================] - 22s 266ms/step - loss: 0.1677\n",
            "Epoch 90/100\n",
            "79/79 [==============================] - 22s 266ms/step - loss: 0.1663\n",
            "Epoch 91/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.1684\n",
            "Epoch 92/100\n",
            "79/79 [==============================] - 22s 260ms/step - loss: 0.1737\n",
            "Epoch 93/100\n",
            "79/79 [==============================] - 22s 260ms/step - loss: 0.1845\n",
            "Epoch 94/100\n",
            "79/79 [==============================] - 22s 264ms/step - loss: 0.1990\n",
            "Epoch 95/100\n",
            "79/79 [==============================] - 22s 264ms/step - loss: 0.2114\n",
            "Epoch 96/100\n",
            "79/79 [==============================] - 22s 265ms/step - loss: 0.2282\n",
            "Epoch 97/100\n",
            "79/79 [==============================] - 22s 266ms/step - loss: 0.2372\n",
            "Epoch 98/100\n",
            "79/79 [==============================] - 22s 266ms/step - loss: 0.2491\n",
            "Epoch 99/100\n",
            "79/79 [==============================] - 22s 261ms/step - loss: 0.2551\n",
            "Epoch 100/100\n",
            "79/79 [==============================] - 22s 261ms/step - loss: 0.2444\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=100, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6de07f8e",
      "metadata": {
        "id": "6de07f8e"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aa6c831",
      "metadata": {
        "id": "0aa6c831"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, characters_from_id, id_from_characters, 1.0)\n",
        "one_step_model1 = OneStep(model, characters_from_id, id_from_characters, 0.9)\n",
        "one_step_model2 = OneStep(model, characters_from_id, id_from_characters, 0.8)\n",
        "one_step_model3 = OneStep(model, characters_from_id, id_from_characters, 0.7)\n",
        "one_step_model4 = OneStep(model, characters_from_id, id_from_characters, 0.6)\n",
        "one_step_model5 = OneStep(model, characters_from_id, id_from_characters, 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39697abc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39697abc",
        "outputId": "5bb5354d-985f-4deb-a0bd-7d5f91eb20cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There they have a way of beating. Sam gived my heart that Gandalf chose many minutes here and there the darkness the horsems of war, free down under the Mines, to us of the sky above the longer steep and the Forest and most stoods in his pocket.\n",
            "     His watch was nearly as quickly as they could. Soon after half way account with light of almost silent, was now too imagined. The birds was lords. There was a fire or craveling through a clink and noon. Then setting it aside, he ran to the edge and peered over the menect of Balin and its fall; the passage twisted tree miles, tired but neither old home and bright. 'There are no hope that for this is the worthy meant, for it is eight,' said stood, and then took something in it. He flugged away from the edges of Amon Hen and uncamed his pocket. They started in their horses listening; and behind it rolling here and the Elves dear to be in his blanket. 'Very seath you are right in the looks and placest of things little a sigh. I have never seen such \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 5.205015420913696\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['There'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qfGIBmgcfhhy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfGIBmgcfhhy",
        "outputId": "d60e92ee-c8d4-4f09-f977-6281b628406b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There they would ever a rest, remembered, but when these are elf-voice, and bent down the river and the flat suspicious of Buckland (alwer-pressed or heard the northern and bore many places. Would not help us to keep so stroken than five gone. Bilbo among the Wise, soon after I am, or we saw against the hunter.'\n",
            "     Aragorn sprang away from the hill, they faded, and suddenly she passed through Arche-toithern-sky. There was no sound. Trembling he looked suddenly from a fire. On the near he began his feet. He felt that he had not heard no sign of any travels and boltestors in Elves; end on the landing stone had fallen in water-doings of night, and their forgiss and dwarves eastward from their thoughts. Frodo stood in the distance they heard again the quirt about them. They could see nothing that minal contained many cliffs, who asked the stone or juddle. Yet should be miles the first rainon and be glad indeed; and now he wields resist him. If gave way off three or of us to take Sam. 'I don't \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 5.088149547576904\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['There'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model1.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KNnejohNfieU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNnejohNfieU",
        "outputId": "21764a26-9b51-491b-8ae9-6c21420a063e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There they have a talk agreen. In the dept since he seemed to remember something; and in the end she departed with young hobbit and reeds by the slope, was now the lord of many sturdy men, and their forgs inco ofening was pass in the wind. An eastward peneats statuen many plains, and from its pages came dimly in the sun.\n",
            "     The sun had gone far and wide that Glóin embarken of a ross, sand somewhere, on the edge of the river-valley and set up before them. The river suddenly thin and seek a face was strength.\n",
            "     `_Care we first entered Merry's! ' said Pippin. 'You won't have a naped your boots of my house,' said Boromir. `It is a high present from all the arswer; and now then a northern lands was left behind, even in Rivendell. We have called the Ring down to death.'\n",
            "     'Destroye_?' cried Frodo. `And what had become of the Mines? Hear will shade a friend of mine friends. Turned Saruman awáre. I could not ride among the streams. But your ring is in his book,' said Aragorn, 'foind in this \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.835484981536865\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['There'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model2.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "POEc59rkfioR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POEc59rkfioR",
        "outputId": "2da886cc-e7ab-4870-f313-9d2c81590481"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There they had all passed through, it was already his by right. This was the song as the last house on the others; though he kept out through a deep ravine that led them somewhere to large. He would soon now, but only remember it argulatching the Ford by the road; so on an edge must need be some great mountains.\n",
            "     Gandalf paused astonished and looked at the stone, and listening for the rustle of valours, and her sight moon; and the flies began to find the Grey Havens, from over the mountains and the door. But when he looked about up and rather shut, and it grows near the shore below.\n",
            "     'They'll be cleared quietly. I never heard of anything yet. In some I naid was dead. And you must go and saw it as my letter. I didn't like it aside, I feel like this, maybe, we were all sake you.'\n",
            "     'I know,' said Sam. 'It's a pity Mr. Baggins drows ahead difficult to the legend, and it would be a dark fire willow!'\n",
            "     'I think I can produce him.'\n",
            "     'Where is he?' says some ordinary hobbits (th \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.856245756149292\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['There'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model3.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9BYvDsL9fiuA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BYvDsL9fiuA",
        "outputId": "4743c56f-af26-41d6-ec9b-56d51877b215"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There they have a pain of a bone of sight alone, all those that he saw was shadowed and falling round again in the mountains. Troll, water for Bilbo, there was a ribbont-bood, and it had been built in the dusk of Amroth, where it is never a rule. But what was it that the Mirror slew much quiet! ' said Sam. `I will diminish, and go ay such a thing could stand to be pares! I wish you were not going into the I new hours. You have seen one of the lore-masters,' said Gandalf. `The passage is blocked behind us now and there the River seems to the point. No folk could they see, and they will not take the Ring itself to wait until nightfall. After all his father was a Baggins. A decent respectally the Sickle was or joint out again. He said that Frodo was looking across lands he had never seen careful that they did not mean to go on again full of plain grey hill, and strode on the bank at the sides, and looked up and down a large accourt:\n",
            "\n",
            "     _For A LOGAffain! ' He murmed out of a decring. I must  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.862099885940552\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['There'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model4.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ECPF4Ob0fi0H",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECPF4Ob0fi0H",
        "outputId": "a44caf9d-755e-4670-9a8b-6319c6877555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There they have a passion for mushrooms, surpassing even him known to me. I have known your friend is!' said Frodo. 'I am not a Baggins, the Nine Sea, and not when he has a pit for certain. It was round solemold, if you do. Before the troll-folk is useless. And if I'me never heard of anything like this rider as stop misings. I wish to learn what has it got in its pocketses?\" he says as soon as it should be, and always dark, and cast them on a fall away sharp ears. Sweeting!\n",
            "\n",
            "     Nothing could be seen all round the house but falling water was loud, and the evening was filled with a thick hedge on the lane. The perish looked straight at the sky was broken over them. The sun was white hummer and looked against the draught: there were still meaning on the shoulder with the hurrying river. In the midst of it had been given the thing hope spoken of.'\n",
            "     `And if that is what you well to do with it?' I'll talk.'\n",
            "     'And no wonder that don't pass I have learned much,' he said in a low voice. 'T \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.856241703033447\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['There'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model5.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sj0sRG8jxXRx",
      "metadata": {
        "id": "sj0sRG8jxXRx"
      },
      "source": [
        "#Text generation was also attempted with [Max Woolf's textgenrnn](https://github.com/minimaxir/textgenrnn), using a smaller text dataset from the script of the Bee Movie. All RNN settings used were the defaults from [the Colaboratory Notebook](https://drive.google.com/file/d/1mMKGnVxirJnqDViH7BDJxFqWrsXlPSoK/view), with the exception of the following changes:\n",
        "#In the training configuration (train_cfg), the number of epochs was increased from 30 to 50, the proportion of input data to train (train_size) was increased from 0.8 to 0.9, and the dropout was increased from 0.0 to 0.1 (to counterbalance the increase in proportion of input data used for training).\n",
        "\n",
        "# See the raw outputs document for the text generated from training textgenrnn on the Bee Movie script.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
